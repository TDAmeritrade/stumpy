{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "### Motif-Only Matrix Profile (MOMP): A Faster Approach to Motif Discovery in Time Series\n",
    "#### *By Joey Higgins*\n",
    "\n",
    "In this tutorial, we will walk through the Motif-Only Matrix Profile (MOMP), an advanced technique for time series motif discovery, as proposed in the [Motif Only Matrix Profile](https://www.dropbox.com/scl/fi/mt8vp7mdirng04v6llx6y/MOMP_DeskTop.pdf?rlkey=gt6u0egagurkmmqh2ga2ccz85&e=1&dl=0) (Keogh, 2024). MOMP combines the computational efficiency of downsampling with lower-bound approximations, pruning irrelevant subsequences, and refining best motif candidates. This results in a significant speedup compared to traditional Matrix Profile algorithms.\n",
    "\n",
    "Ultimately, we will walk through the MOMP algorithm with enhancements such as the K-Triangular Inequality Profile (KTIP) and multiresolution pruning. We will also test the performance of MOMP on real-world datasets and compare it with other matrix profile algorithms like STOMP.\n",
    "\n",
    "### Objectives:\n",
    "1. Understand how to compute the Lower Bound Matrix Profile (lbMP) and KTIP for aggressive pruning.\n",
    "2. Implement multiresolution pruning to refine motif search from coarse to fine resolution.\n",
    "3. Refine the best-so-far (bsf) motif distance with exact distance calculations and cohort point adjustments.\n",
    "4. Run performance comparisons on real-world datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Definitions](#definitions)\n",
    "3. [Implementation](#implementation)\n",
    "   - [Step 1: K-Triangular Inequality Profile Algorithm (KTIP)](#step-1-computing-k-triangular-inequality-profile-ktip)\n",
    "   - [Step 2: Piecewise Aggregate Approximation (PAA)](#step-2-piecewise-aggregate-approximation-paa)\n",
    "   - [Step 3: Lower Bound Matrix Profile (lbMP)](#step-3-computing-the-lower-bound-matrix-profile-lbmp)\n",
    "   - [Step 4: Best-So-Far (bsf) Motif](#step-4-best-so-far-local-refinement)\n",
    "   - [Step 5: Pruning Algorithm](#step-5-pruning-algorithm)\n",
    "   - [Step 6: Final Exact Matrix Profile Calculation](#step-6-final-exact-matrix-profile-calculation)\n",
    "4. [Performance Comparisons](#performance-comparisons)\n",
    "5. [Conclusion](#conclusion)\n",
    "6. [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOMP Algorithm Overview\n",
    "\n",
    "Motif-Only Matrix Profile (MOMP) improves traditional motif discovery by aggressively pruning subsequences using the **Lower Bound Matrix Profile (lbMP)** and the **K-Triangular Inequality Profile (KTIP)**. Starting with a coarse downsampling rate, the algorithm performs multiresolution pruning, gradually refining the motif search and recalculating the exact matrix profile for unpruned subsequences at the final stage.\n",
    "\n",
    "### Key Enhancements:\n",
    "- **K-Triangular Inequality Profile (KTIP)**: KTIP leverages the triangular inequality to refine subsequence distance estimates and prune unpromising pairs.\n",
    "- **Lower Bound Matrix Profile (lbMP)**: The lbMP stores rough estimates of subsequence distances, allowing for pruning.\n",
    "- **Multiresolution Pruning**: The motif search begins with coarse approximations and progressively increases resolution to focus on promising subsequences.\n",
    "- **Cohort Points**: These are anchor points used in the final motif refinement stage to ensure local subsequences are correctly aligned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MOMP Algorithm](docs/images/MOMP_algorithm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "\n",
    "Before we dive into the implementation, letâ€™s define some key terms that will help you understand the MOMP process:\n",
    "\n",
    "- **Best-So-Far (bsf)**: The smallest distance between any two subsequences that has been found so far. As the algorithm progresses, the bsf is updated whenever a smaller distance is discovered.\n",
    "- **Cohort Points**: Cohort points are the anchor subsequences that help refine the best-so-far (bsf) motif distance during the final stages of the algorithm.\n",
    "- **Downsampling**: The process of reducing the resolution of the time series by averaging over groups of data points. Downsampling speeds up initial calculations by working with a coarser representation of the time series.\n",
    "- **dsr**: Downsampling Rate, or the factor by which the time series is reduced. For example, a dsr of 2 means that every two points in the original time series are averaged into one point.\n",
    "- **Lower Bound**: A rough estimate of the minimum possible distance between subsequences, computed using the downsampled time series. Lower bounds are used to quickly prune unpromising subsequences before calculating the exact distance.\n",
    "- **lbMP**: Lower Bound Matrix Profile, which stores the lower bound distances between subsequences in the time series. It helps in identifying which subsequences can be pruned.\n",
    "- **Matrix Profile (MP)**: A data structure that stores the z-normalized Euclidean distance between each subsequence in a time series and its nearest neighbor. The MP is used to efficiently identify motifs in the data.\n",
    "- **Motif**: A repeating pattern in a time series that occurs at least twice. Motifs are subsequences with minimal Euclidean distances between them.\n",
    "- **Multiresolution Pruning**: This refers to the process of starting the motif search at a coarse downsampling rate, pruning subsequences based on lower bounds, and iteratively refining the search at finer resolutions.\n",
    "- **Piecewise Aggregate Approximation (PAA)**: A dimensionality reduction technique that divides a subsequence into equal-sized segments, calculating the mean of each segment. PAA creates a simplified representation of the subsequence, retaining its key shape features while reducing noise.\n",
    "- **Pruning**: The process of eliminating subsequences that cannot possibly be motifs based on their lower bound distance. If the lower bound of a subsequence's distance is already greater than the current bsf, it is pruned.\n",
    "\n",
    "These concepts are essential for understanding how MOMP works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Started\n",
    "Importing all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import stumpy\n",
    "import math\n",
    "\n",
    "np.set_printoptions(linewidth=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Computing K-Triangular Inequality Profile (KTIP)\n",
    "\n",
    "The first step is to calculate the lower bound distances between subsequences in the downsampled time series using the K-Triangular Inequality Profile (KTIP) algorithm. KTIP computes a matrix of lower bound distances at various downsampling rates, leveraging powers of 2 to capture increasingly accurate estimates with minimal computation. These lower bounds help us quickly identify which parts of the time series are likely irrelevant by providing a fast approximation of distances. This allows us to efficiently \"prune\" or ignore segments that are unlikely to contain the best matches, focusing our search on the most promising regions.\n",
    "\n",
    "\n",
    "This implementation of the K-Triangular Inequality Profile (KTIP) algorithm is based on **Table 3: K-Triangular Inequality Profile Algorithm** in the referenced research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeKTIP(T, m, dsr0):\n",
    "    \"\"\"\n",
    "    Compute the K-Triangular Inequality Profile (KTIP).\n",
    "    \n",
    "    Parameters:\n",
    "    - T: Input time series (array-like)\n",
    "    - m: Subsequence length (integer)\n",
    "    - dsr0: Initial downsampling rate (integer)\n",
    "    \n",
    "    Returns:\n",
    "    - ktip: Lower bound matrix profile\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(T)\n",
    "    num_diags = int(math.log2(dsr0)) + 1  # Number of diagonal levels based on dsr0\n",
    "    ktip = np.full((n - m + 1, num_diags), np.nan)  # Initialize ktip with NaN values\n",
    "    temp = np.full((n - m + 1), np.inf)  # Initialize temp with infinity values\n",
    "    \n",
    "    for diag in range(1, dsr0 + 1):\n",
    "        for rr in range(n - m - diag + 2):\n",
    "            cc = rr + diag\n",
    "            if cc >= len(T) - m + 1:\n",
    "                break  # Avoids accessing out-of-bounds indices\n",
    "            dist = np.sqrt(np.sum((T[rr:rr + m] - T[cc:cc + m]) ** 2))\n",
    "            \n",
    "            # Update temp for minimum distances\n",
    "            if dist < temp[rr]:\n",
    "                temp[rr] = dist\n",
    "\n",
    "            if dist < temp[cc]:\n",
    "                temp[cc] = dist\n",
    "        \n",
    "        # Store temp values in ktip at log2(diag) positions if diag is a power of 2\n",
    "        if math.log2(diag).is_integer():\n",
    "            ktip[:, int(math.log2(diag))] = temp\n",
    "    \n",
    "    return ktip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Testing the KTIP algorithm.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KTIP Matrix:\n",
      " [[1.73205081 1.73205081 1.73205081]\n",
      " [1.73205081 1.73205081 1.73205081]\n",
      " [1.73205081 1.73205081 1.73205081]\n",
      " [1.73205081 1.73205081 1.73205081]\n",
      " [1.73205081 1.73205081 1.73205081]\n",
      " [1.73205081 1.73205081 1.73205081]\n",
      " [1.73205081 1.73205081 1.73205081]\n",
      " [1.73205081 1.73205081 1.73205081]]\n"
     ]
    }
   ],
   "source": [
    "# Testing the KTIP algorithm\n",
    "T = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])  # Sample time series\n",
    "m = 3  # Subsequence length\n",
    "dsr0 = 4  # Initial downsampling rate\n",
    "\n",
    "ktip_result = computeKTIP(T, m, dsr0)\n",
    "print(\"KTIP Matrix:\\n\", ktip_result)\n",
    "\n",
    "# Basic checks\n",
    "assert ktip_result.shape == (len(T) - m + 1, int(math.log2(dsr0)) + 1), \"Output dimensions incorrect.\"\n",
    "assert not np.isnan(ktip_result).all(), \"All values in the result are NaN.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Piecewise Aggregate Approximation (PAA)\n",
    "The Piecewise Aggregate Approximation (PAA) is a key preprocessing technique in the motif discovery process. PAA simplifies each subsequence by dividing it into equal-sized segments and computing the mean of each segment. This dimensionality reduction step retains the essential shape characteristics of the time series while reducing noise, making it easier to perform accurate similarity matching with less computational effort.\n",
    "\n",
    "- By using PAA, we create a lower-resolution representation of the subsequences that balances detail with efficiency. \n",
    "- This allows for faster lower-bound calculations and improved pruning performance, as irrelevant or noisy variations within each segment are minimized.\n",
    "\n",
    "The Piecewise Aggregate Approximation (PAA) is calculated as:\n",
    "\n",
    "$$\n",
    "\\bar{t}_i = \\frac{k}{n} \\sum_{j=\\frac{n}{k}(i-1) + 1}^{\\frac{n}{k} \\, i} t_j\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ \\bar{t}_i $ represents the PAA-transformed value for segment $ i $\n",
    "- $ k $ is the number of segments\n",
    "- $ n $ is the length of the time series\n",
    "- $ t_j $ represents the original time series data point\n",
    "\n",
    "This implementation of the Piecewise Aggregate Approximation (PAA) is based on **Definition 4: Section IV (\"Lower Bounding the Matrix Profile\")** in the referenced research paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PAA(T, dsr):\n",
    "    \"\"\"\n",
    "    Piecewise Aggregate Approximation (PAA) for downsampling.\n",
    "\n",
    "    Parameters:\n",
    "    T (array-like): The time series data to downsample.\n",
    "    dsr (int): Downsampling rate (window size for each segment).\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Array of PAA-transformed values.\n",
    "    \"\"\"\n",
    "    n = len(T)  # Length of the input time series\n",
    "    num_segments = n // dsr  # Number of segments after downsampling\n",
    "    \n",
    "    # Calculate the mean for each segment and store it in the paa array\n",
    "    paa = np.array([\n",
    "        np.mean(T[i * dsr:(i + 1) * dsr])  # Mean of segment i\n",
    "        for i in range(num_segments)       # Iterate over all segments\n",
    "    ])\n",
    "    \n",
    "    return paa  # Return the PAA-transformed array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Testing the PAA algorithm.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling rate 2 - PAA Result: [1.5 3.5 5.5 7.5 9.5]\n",
      "Downsampling rate 3 - PAA Result: [2. 5. 8.]\n",
      "Downsampling rate 5 - PAA Result: [3. 8.]\n"
     ]
    }
   ],
   "source": [
    "# Sample time series data\n",
    "T = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# Test with downsampling rate dsr = 2\n",
    "dsr = 2\n",
    "result_dsr2 = PAA(T, dsr)\n",
    "print(\"Downsampling rate 2 - PAA Result:\", result_dsr2)\n",
    "\n",
    "# Test with downsampling rate dsr = 3\n",
    "dsr = 3\n",
    "result_dsr3 = PAA(T, dsr)\n",
    "print(\"Downsampling rate 3 - PAA Result:\", result_dsr3)\n",
    "\n",
    "# Test with downsampling rate dsr = 5\n",
    "dsr = 5\n",
    "result_dsr5 = PAA(T, dsr)\n",
    "print(\"Downsampling rate 5 - PAA Result:\", result_dsr5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Computing the Lower Bound Matrix Profile (lbMP)\n",
    "\n",
    "In this step, we compute the Lower Bound Matrix Profile (lbMP), which provides a preliminary estimate of the similarity between subsequences in the time series. The lbMP acts as a fast filtering mechanism by using lower-bound calculations to pre-screen the subsequences. This enables us to avoid unnecessary computations by immediately discarding regions with low potential for being the closest match.\n",
    "\n",
    "- The lbMP algorithm calculates a lower bound on the Euclidean distances between subsequences, allowing the system to focus computational resources on the most likely candidates for motifs. \n",
    "- By systematically downsampling and applying the lower-bound function, we can reduce the time complexity significantly without sacrificing accuracy in motif detection.\n",
    "\n",
    "This implementation of the Lower Bound Matrix Profile (lbMP) is based on **Table 4: Lower Bound Matrix Profile Algorithm** in the referenced research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLBMP(T, m, dsr, ip):\n",
    "    \"\"\"\n",
    "    Compute the Lower Bound Matrix Profile (LBMP) for MOMP.\n",
    "\n",
    "    Parameters:\n",
    "        T (numpy.ndarray): Input time series\n",
    "        m (int): Subsequence length\n",
    "        dsr (int): Downsampling rate\n",
    "        ip (numpy.ndarray): Intermediate profile from KTIP\n",
    "\n",
    "    Returns:\n",
    "        tuple: (Lower Bound Matrix Profile (numpy.ndarray), local_bsf (float, tuple))\n",
    "    \"\"\"\n",
    "    dT = PAA(T, dsr)  # Step 2: Downsampled time series using PAA\n",
    "    amp = stumpy.stump(dT, m // dsr)[:, 0]  # Step 3: Compute approximate MP with STUMP\n",
    "    lbMP = np.full(len(amp), np.nan)  # Initialize LBMP\n",
    "\n",
    "    # Track local best-so-far (bsf) distance and indices\n",
    "    min_distance = np.inf\n",
    "    min_indices = (0, 0)\n",
    "\n",
    "    # Calculate lbMP with KTIP-based pruning\n",
    "    for i in range(len(amp)):\n",
    "        max_dist = -np.inf\n",
    "        for j in range(len(amp)):\n",
    "            if i != j:\n",
    "                dist = amp[i] - ip[i] - ip[j]\n",
    "                if dist > max_dist:\n",
    "                    max_dist = dist\n",
    "\n",
    "                # Track minimum distance (best-so-far)\n",
    "                if dist < min_distance:\n",
    "                    min_distance = dist\n",
    "                    min_indices = (i, j)\n",
    "\n",
    "        lbMP[i] = max_dist\n",
    "\n",
    "    # Upsample lbMP to match original time series length\n",
    "    lbMPdsr = np.repeat(lbMP, dsr)[:len(T) - m + 1]\n",
    "    \n",
    "    return lbMPdsr, (min_distance, min_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Testing the lbMP algorithm.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampled Lower Bound Matrix Profile: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Minimum LBMP and Indices: (np.float64(0.0), (0, 1))\n"
     ]
    }
   ],
   "source": [
    "# Sample test function for computeLBMP\n",
    "\n",
    "# Sample time series data\n",
    "T = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n",
    "m = 6  # Subsequence length\n",
    "dsr = 2  # Downsampling rate\n",
    "ip = np.zeros(len(T) // dsr)  # Sample intermediate profile, matching the downsampled length\n",
    "\n",
    "# Run the computeLBMP function\n",
    "lbMPdsr, min_lbMP = computeLBMP(T, m, dsr, ip)\n",
    "\n",
    "# Print the results for verification\n",
    "print(\"Upsampled Lower Bound Matrix Profile:\", lbMPdsr)\n",
    "print(\"Minimum LBMP and Indices:\", min_lbMP)\n",
    "\n",
    "# Assertions for testing\n",
    "assert isinstance(lbMPdsr, np.ndarray), \"lbMPdsr should be a numpy array\"\n",
    "assert isinstance(min_lbMP, tuple) and len(min_lbMP) == 2, \"min_lbMP should be a tuple with two elements\"\n",
    "assert isinstance(min_lbMP[0], (float, np.float64)), \"First element of min_lbMP should be a float\"\n",
    "assert isinstance(min_lbMP[1], tuple) and len(min_lbMP[1]) == 2, \"Second element of min_lbMP should be a tuple of two indices\"\n",
    "assert len(lbMPdsr) == len(T) - m + 1, \"Length of lbMPdsr should match len(T) - m + 1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Best-so-far Local Refinement\n",
    "After generating an initial list of candidate motifs through lower-bound filtering, we refine these candidates by applying the Best-so-far Local Refinement (bsf) algorithm. This refinement step enhances the accuracy of our motif search by recalculating distances for each candidate subsequence and updating our current best match as we go.\n",
    "\n",
    "- The bsf algorithm evaluates each candidate motif in the context of its local neighborhood, aiming to improve the precision of our nearest-neighbor estimates. \n",
    "- This local refinement ensures that the final motif location is as accurate as possible, significantly reducing false positives that may have passed through the lower-bound filter.\n",
    "\n",
    "This implementation of the Best-so-far Local Refinement (bsf) follows **Table 5: Best-so-far Local Refinement** in the referenced research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refineBSFloc(T, m, dsr, local_bsf, bsf):\n",
    "    \"\"\"\n",
    "    Refines the best-so-far (bsf) motif distance locally.\n",
    "\n",
    "    Parameters:\n",
    "    T (array-like): The time series data.\n",
    "    m (int): The subsequence length for motif search.\n",
    "    dsr (int): Downsampling rate.\n",
    "    local_bsf (tuple): Tuple containing indices of candidate motif pairs.\n",
    "    bsf (float): Current best-so-far distance.\n",
    "\n",
    "    Returns:\n",
    "    float, int: Updated best-so-far distance and the location of the closest match.\n",
    "    \"\"\"\n",
    "    T = np.asarray(T, dtype=float)  # Convert the time series to a numpy array for consistency\n",
    "    \n",
    "    # Ensure dsr is an integer for indexing purposes\n",
    "    dsr = int(dsr)\n",
    "    \n",
    "    i = local_bsf[0]\n",
    "    j = local_bsf[1]\n",
    "\n",
    "    # Step 2: Define the segments segA and segB by slicing the time series around indices i and j\n",
    "    segA = T[i: i + m + dsr - 1]  # Segment starting at index i\n",
    "    segB = T[j: j + m + dsr - 1]  # Segment starting at index j\n",
    "\n",
    "    # Step 3: Use stumpy.mstump for multidimensional matrix profile calculation\n",
    "    stacked_segments = np.vstack([segA, segB])  # Stack the segments for efficient processing\n",
    "    mp, _ = stumpy.mstump(stacked_segments, m)  # Compute the matrix profile for the stacked segments\n",
    "\n",
    "    # Step 4: Find the location of the minimum value in the matrix profile\n",
    "    minloc = np.argmin(mp[:, 0])  # Get the index of the minimum value in the profile\n",
    "\n",
    "    # Step 5: Update bsf if a smaller motif distance is found\n",
    "    if np.min(mp[:, 0]) < bsf:\n",
    "        bsf = mp[minloc, 0]  # Update bsf with the new minimum distance\n",
    "    \n",
    "    # Return the updated best-so-far distance and the location of the best match\n",
    "    return bsf, minloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Testing the bsf algorithm.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Best-so-far (bsf): 5.0\n",
      "Updated bsf location: 0\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "T = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])  # Sample time series data\n",
    "m = 3  # Subsequence length\n",
    "dsr = 2  # Downsampling rate\n",
    "local_bsf = (2, 6)  # Example location from previous step\n",
    "bsf = 5.0  # Initial best-so-far value\n",
    "\n",
    "updated_bsf, bsf_loc = refineBSFloc(T, m, dsr, local_bsf, bsf)\n",
    "print(\"Updated Best-so-far (bsf):\", updated_bsf)\n",
    "print(\"Updated bsf location:\", bsf_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Pruning Algorithm\n",
    "The Pruning Algorithm is the final step in narrowing down our motif candidates, enabling us to discard subsequences that are unlikely to contain the closest match. By pruning low-potential regions, we streamline the search and further reduce computational overhead.\n",
    "\n",
    "- This pruning process works by analyzing the remaining subsequences after the Best-so-far Local Refinement. \n",
    "- The algorithm eliminates any subsequences whose lower bound distance exceeds the current best match, ensuring we only retain the most promising candidates. \n",
    "- This step is particularly effective in large datasets, where minimizing unnecessary comparisons can lead to substantial performance gains.\n",
    "\n",
    "This implementation of the Pruning Algorithm is based on **Table 6: Pruning Algorithm** in the referenced research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(T, m, lbMP, bsf):\n",
    "    \"\"\"\n",
    "    Prunes the time series based on the Lower Bound Matrix Profile (lbMP) and the best-so-far (bsf) distance.\n",
    "\n",
    "    Parameters:\n",
    "    T (array-like): The time series data.\n",
    "    m (int): The subsequence length for motif search.\n",
    "    lbMP (array-like): Lower Bound Matrix Profile for pruning.\n",
    "    bsf (float): Current best-so-far distance for pruning.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Array of pruned subsequences from the time series.\n",
    "    \"\"\"\n",
    "    \n",
    "    prnT = []  # Initialize an empty list to store pruned subsequences\n",
    "    \n",
    "    # Locate indices in lbMP where values are less than or equal to the best-so-far (bsf) threshold\n",
    "    tgts = np.where(lbMP <= bsf)[0]\n",
    "    # tgts = [i for i in lbMP if i <= bsf]\n",
    "    \n",
    "    # Iterate over each target index in tgts\n",
    "    for t in tgts:\n",
    "        # Extract the subsequence of length 'm' starting at index 't' and append to prnT\n",
    "        # print(t, T, tgts)\n",
    "        prnT.append(T[t:t + m])\n",
    "    \n",
    "    # Convert the list of pruned subsequences to a NumPy array for consistency and return\n",
    "    return np.array(prnT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Testing the pruning algorithm.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Time Series: [[ 1  2  3]\n",
      " [ 3  4  5]\n",
      " [ 5  6  7]\n",
      " [ 7  8  9]\n",
      " [ 8  9 10]]\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "T = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])  # Sample time series data\n",
    "m = 3  # Subsequence length\n",
    "lbMP = np.array([2.5, 5.0, 1.0, 6.0, 2.0, 4.5, 1.5, 3.0])  # Lower bound matrix profile\n",
    "bsf = 3.0 # Example bsf containing a None value\n",
    "\n",
    "pruned_series = prune(T, m, lbMP, bsf)\n",
    "print(\"Pruned Time Series:\", pruned_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: MOMP (Motif-Only Matrix Profile) Algorithm\n",
    "The Motif-Only Matrix Profile (MOMP) algorithm is designed to efficiently identify recurring patterns (motifs) in a time series without calculating the full matrix profile. This selective approach enables us to focus on the most significant motifs, reducing computational demands by skipping unnecessary comparisons.\n",
    "\n",
    "- The MOMP algorithm starts by computing an initial approximation of motifs, leveraging the Piecewise Aggregate Approximation (PAA) to simplify the time series.\n",
    "- It then applies lower bound pruning techniques, such as the Lower Bound Matrix Profile (lbMP) and K-Triangular Inequality Profile (KTIP), to discard subsequences unlikely to contain close motif matches.\n",
    "- Finally, MOMP iteratively refines motif candidates by calculating the exact motif distances, using best-so-far tracking to progressively narrow down to the closest matches.\n",
    "\n",
    "This implementation of the MOMP algorithm is based on **Table 2: The MOMP Algorithm** in the referenced research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MOMP(T, m):\n",
    "    \"\"\"\n",
    "\n",
    "    Motif-Only Matrix Profile (MOMP) algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "        T (list): Input time series\n",
    "        m (int): Subsequence length\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Minimum distance (float), Motif location (tuple)\n",
    "    \"\"\"\n",
    "    T = np.array(T)  # Convert T to a numpy array\n",
    "    T0 = T\n",
    "    dsr = max(2, int(m / 32))  # Set initial coarse downsample rate, ensure >= 2\n",
    "    bsf = float('inf')\n",
    "    print(f\"T: {T}\")\n",
    "\n",
    "    # Step 4: Compute full K-Triangular Inequality Profile (KTIP) using computeKTIP (Table 3)\n",
    "    full_ktip = computeKTIP(T0, m, dsr)\n",
    "    print(f\"full_ktip: {full_ktip}\")\n",
    "    \n",
    "    while True:\n",
    "        # Step 6: Select KTIP values for current downsampling rate\n",
    "        ip = full_ktip[:, int(np.log2(dsr))]\n",
    "        print(f\"ip: {ip}\")\n",
    "\n",
    "        # Step 7: Compute Lower Bound Matrix Profile (LBMP) using computeLBMP (Table 4)\n",
    "        lbMP, local_bsf = computeLBMP(T, m, dsr, ip)[1]\n",
    "        # local_bsf = (local_bsf[1])[0]\n",
    "        print(f\"lbMP: {lbMP}\")\n",
    "        print(f\"local_bsf: {local_bsf}\")\n",
    "\n",
    "        # Step 8: Refine best-so-far using refineBSFloc (Table 5)\n",
    "        bsf = refineBSFloc(T0, m, dsr, local_bsf, bsf)\n",
    "        print(f\"bsf: {bsf}\")\n",
    "\n",
    "        # Step 9: Prune the time series using prune (Table 6)\n",
    "        prnT = prune(T0, m, lbMP, bsf)\n",
    "        print(f\"prnT: {prnT}\")\n",
    "        \n",
    "        # Update T with pruned time series\n",
    "        T = prnT\n",
    "        \n",
    "        # Step 11: Halve the downsampling rate, stop if dsr reaches 1\n",
    "        dsr = max(1, dsr // 2)\n",
    "        if dsr == 1:\n",
    "            # Step 13: Compute exact Matrix Profile to finalize motifs\n",
    "            mp, motifloc = stumpy.mstump(T, m)  # Using STUMP as a fallback for SCAMP\n",
    "            \n",
    "            return np.min(mp[:, 0]), (motifloc[0], motifloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Testing the MOMP algorithm.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: [0.2 0.5 0.7 0.4 0.9 1.2 0.6 0.8 1.1 0.3 0.2 0.9 1.5 0.7 0.8 1. ]\n",
      "full_ktip: [[1.02469508 1.02469508]\n",
      " [1.02469508 1.02469508]\n",
      " [1.25299641 1.25299641]\n",
      " [1.25299641 1.25299641]\n",
      " [1.40356688 1.40356688]\n",
      " [1.44222051 1.44222051]\n",
      " [1.50996689 1.50996689]\n",
      " [1.50996689 1.50996689]\n",
      " [1.50996689 1.50996689]]\n",
      "ip: [1.02469508 1.02469508 1.25299641 1.25299641 1.40356688 1.44222051 1.50996689 1.50996689 1.50996689]\n",
      "lbMP: -1.5447723871203547\n",
      "local_bsf: (4, 2)\n",
      "bsf: (inf, np.int64(0))\n",
      "prnT: [[0.2 0.5 0.7 0.4 0.9 1.2 0.6 0.8]\n",
      " [0.5 0.7 0.4 0.9 1.2 0.6 0.8 1.1]]\n",
      "Minimum Motif Distance: inf\n",
      "Motif Location: (array([-1]), array([-1]))\n"
     ]
    }
   ],
   "source": [
    "T = np.array([0.2, 0.5, 0.7, 0.4, 0.9, 1.2, 0.6, 0.8, 1.1, 0.3, 0.2, 0.9, 1.5, 0.7, 0.8, 1.0]) # Sample time series data\n",
    "m = 8  # Updated subsequence length to be greater than 3\n",
    "\n",
    "# Call the MOMP function\n",
    "min_distance, motif_location = MOMP(T, m)\n",
    "\n",
    "# Output the results\n",
    "print(\"Minimum Motif Distance:\", min_distance)\n",
    "print(\"Motif Location:\", motif_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True minimum motif distance (without pruning): 6.563890342412331\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import stumpy  # Ensure you have stumpy installed\n",
    "\n",
    "# Generate a synthetic time series with a known repeating pattern\n",
    "def generate_synthetic_series(length=1000, motif_length=50):\n",
    "    motif = np.sin(np.linspace(0, 3.14, motif_length))  # Simple sinusoidal motif\n",
    "    time_series = np.random.rand(length)\n",
    "    insert_pos = np.random.randint(0, length - motif_length)\n",
    "    time_series[insert_pos:insert_pos + motif_length] = motif\n",
    "    return time_series, insert_pos, insert_pos + motif_length\n",
    "\n",
    "# Generate the synthetic series\n",
    "T, motif_start, motif_end = generate_synthetic_series()\n",
    "\n",
    "# Run the full matrix profile for comparison\n",
    "m = 50  # Define the length of the subsequence to search\n",
    "mp = stumpy.stump(T, m)\n",
    "true_motif_distance = np.min(mp[:, 0])\n",
    "print(\"True minimum motif distance (without pruning):\", true_motif_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(inf), 6.563890342412331)"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure both distances are floats\n",
    "momp_distance = float(momp_distance) if isinstance(momp_distance, (np.ndarray, list)) else momp_distance\n",
    "true_motif_distance = float(true_motif_distance) if isinstance(true_motif_distance, (np.ndarray, list)) else true_motif_distance\n",
    "\n",
    "momp_distance, true_motif_distance\n",
    "\n",
    "\n",
    "# # Now perform the comparison\n",
    "# assert np.isclose(momp_distance, true_motif_distance, atol=0.01), \"MOMP distance differs significantly from full matrix profile.\"\n",
    "# print(\"MOMP test passed for synthetic motif.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we explored how the Motif-Only Matrix Profile (MOMP) algorithm speeds up motif discovery by using downsampling and lower bounds to prune irrelevant subsequences. This approach makes motif discovery scalable even for very large time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Shahcheraghi, Maryam and Keogh, Eamonn et al. (2024) Matrix Profile XXXI: Motif-Only Matrix Profile: Orders of Magnitude Faster. ICDM: TBD. [Link](https://www.dropbox.com/scl/fi/mt8vp7mdirng04v6llx6y/MOMP_DeskTop.pdf?rlkey=gt6u0egagurkmmqh2ga2ccz85&e=1&dl=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stumpy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
